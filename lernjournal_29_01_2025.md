# Lernjournal ‚Äì LU02b: Vertikale und horizontale Verteilung

## Kurzbeschrieb
Im Theorieblock LU02b behandelten wir die Themen **vertikale und horizontale Verteilung** in verteilten Systemen. Dabei ging es darum, wie Aufgaben und Ressourcen innerhalb eines Systems organisiert und verteilt werden k√∂nnen. Die vertikale Verteilung beschreibt die Aufteilung von Aufgaben auf verschiedene Schichten oder Ebenen (z.B. Pr√§sentations-, Anwendungs- und Datenbankschicht), w√§hrend die horizontale Verteilung die Vervielf√§ltigung gleicher Komponenten √ºber mehrere Knoten hinweg meint. Wir haben uns angeschaut, wie diese beiden Konzepte in realen Systemen kombiniert eingesetzt werden k√∂nnen. Unser Beispiel war die schweizer Post, ahand welcher wir aufgezeigt haben wie ein verteiltes System funktioniert.

## Lernerfolge
Ich habe durch diesen Block ein besseres Verst√§ndnis daf√ºr gewonnen, **wann und warum** man Systeme vertikal oder horizontal verteilt. Besonders wichtig fand ich die Unterscheidung zwischen **horizontaler und vertikaler Skalierung**, die jeweils unterschiedliche Anforderungen und Herausforderungen mit sich bringen. Ich konnte mir durch die Beispiele (z.B. Webshop und SETI@home) gut vorstellen, wie solche Architekturen in der Praxis aussehen. Zus√§tzlich habe ich gelernt, dass hybride Ans√§tze oft notwendig sind, um die Vorteile beider Methoden zu kombinieren.

## Lernstrategie
Ich bin beim Lernen so vorgegangen, dass ich die wichtigsten Begriffe und Konzepte w√§hrend dem Unterricht **stichwortartig notiert** und anschliessend mit eigenen Worten zusammengefasst habe. Das hilft mir, die Inhalte besser aufzunehmen. Das Erarbeiten von Praxisbeispielen hat mir sehr geholfen, die Theorie greifbar zu machen.

## Fazit
Durch diesen Unterrichtsblock habe ich erkannt, wie entscheidend eine gute Systemarchitektur f√ºr die **Skalierbarkeit und Stabilit√§t** von Anwendungen ist. Meine Lernstrategie mit eigenen Notizen hat sich als sehr effektiv erwiesen, und ich werde sie auch bei zuk√ºnftigen Theoriebl√∂cken weiter anwenden. F√ºr die n√§chsten Learning Units nehme ich mir vor, zus√§tzlich noch mehr auf **praktische Beispiele und Anwendungen** zu achten, um die Theorie noch besser mit der Realit√§t verkn√ºpfen zu k√∂nnen.

---
![skalierung image](./img/skalierung.jpg)
---

## üìò Glossar


**Vertikale Skalierung**  
Leistungssteigerung eines **einzelnen Systems** durch Aufr√ºsten der Hardware (z.B. mehr RAM, st√§rkere CPU). Gut f√ºr einfache Verwaltung, aber begrenzt in der Erweiterbarkeit.

**Horizontale Skalierung**  
Erweiterung der Systemleistung durch **Hinzuf√ºgen zus√§tzlicher Instanzen** oder Server. Bietet bessere Skalierbarkeit und Ausfallsicherheit.

**Verteiltes System**  
Ein System, das aus mehreren **miteinander verbundenen, eigenst√§ndigen Computern** besteht, die zusammenarbeiten, um eine gemeinsame Aufgabe zu erf√ºllen.

**Hybrid-Skalierung**  
Kombination aus vertikaler und horizontaler Skalierung, um die Vorteile beider Methoden zu nutzen ‚Äì h√§ufig in komplexen Systemarchitekturen eingesetzt.

**Loadbalancing**  
Die gleichm√§ssige Verteilung von Traffic auf mehrere Nodes, um √úberlastungen zu vermeiden und die Leistung zu optimieren.

**Ausfallsicherheit**  
F√§higkeit eines Systems, **trotz Fehlern oder Ausf√§llen einzelner Komponenten** weiterhin zuverl√§ssig zu funktionieren. -> Replica Funktion in Docker Stack

# Lernjournal ‚Äì RESTful Webservices, Flask-RESTful & AJAX


---

##  Kurzbeschrieb
In diesem Unterrichtsblock ging es um die Grundlagen von RESTful Webservices und deren praktische Umsetzung mit dem Python-Framework Flask-RESTful. Zudem wurde AJAX als Technik zur asynchronen Daten√ºbertragung im Browser eingef√ºhrt. Ich habe gelernt, wie man eine REST-API erstellt, wie man Anfragen strukturiert und verarbeitet, und wie man mit `fetch()` Daten vom Server laden kann, ohne die Seite neu zu laden.

---

##  Lernerfolge

- Ich verstehe nun, was einen RESTful Webservice ausmacht: Ressourcen, URI, HTTP Methoden (GET, POST, PUT, DELETE) und Statuscodes.
- Ich kann einfache APIs mit Flask-RESTful schreiben und weiss, wie ich Ressourcenklassen implementiere.
```python
class Bug(Resource):
    def get(self):
        if not bugs:
            return {"message": "Keine Bugs gefunden. Dein Code l√§uft... f√ºr jetzt."}, 200
        return {"bugs": bugs}, 200

    def post(self):
        bug_data = request.json
        bug_description = bug_data.get("description", "Unbekannter Bug")
        bugs.append(bug_description)
        return {
            "message": f"Bug gespeichert: '{bug_description}'. Gl√ºckwunsch, du hast gerade technische Schulden produziert!",
            "total_bugs": len(bugs)
        }, 201
```
- Ich kenne den Unterschied zwischen Query-Parametern (z.B. in der URL enthalten) und Formular-Parametern (z.B. im Body).
- Ich habe verstanden, wie `fetch()` funktioniert und wie es verwendet wird, um eine Textdatei dynamisch in eine Webseite zu laden.
- Ich kann die Bedeutung von Statuscodes wie `200 OK`, `404 Not Found` oder `500 Internal Server Error` einordnen und anwenden.

---

##  Lernstrategie

Ich habe den Unterricht aufmerksam verfolgt und mir Notizen gemacht. Besonders hilfreich war f√ºr mich das Schreiben eines eigenen kleinen Webservices in Flask mit einer `HelloWorld`-Ressource. Ich habe die Beispiele mit eigenen Parametern erweitert, um ein besseres Gef√ºhl f√ºr den Datenfluss zu bekommen. Danach habe ich die AJAX-Beispiele Schritt f√ºr Schritt nachgebaut und ver√§ndert, um deren Funktionsweise zu verstehen. Ich habe auch viel mit Konsolenausgaben und `print()`-Statements gearbeitet, um zu sehen, wann welcher Teil des Codes aktiv ist (und vorallem weil ich den Debugger immer noch nicht wirklich effizient brauchen kann).

---

## Fazit

Durch die praktische Arbeit mit Flask-RESTful und AJAX habe ich ein besseres Verst√§ndnis f√ºr die Kommunikation zwischen Frontend und Backend bekommen ohne State speichern zu k√∂nnen.

---
![Restful Logo](./img/flask_restful.png)
---
## Glossar

- **REST**: Ein Architekturstil f√ºr Webservices, bei dem Ressourcen √ºber HTTP eindeutig per URI angesprochen werden.
- **URI**: Eine eindeutige Adresse, unter der eine Ressource im Web erreichbar ist (z.B. `/api/user/1`).
- **HTTP-Methoden**: Befehle wie GET, POST, PUT und DELETE, mit denen Clients dem Server mitteilen, was sie tun m√∂chten.
- **Statuscode**: Eine Antwort vom Server, die den Zustand der Anfrage beschreibt ‚Äì z.B. `200 OK` f√ºr erfolgreich oder `404 Not Found` f√ºr eine nicht gefundene Ressource. Mein pers√∂nlicher Lieblingsstatuscode ist aber `503 Service Unavailable`, weil sich mein Gehirn aktuell genau so f√ºhlt.
- **Query-Parameter**: Daten, die direkt in der URL √ºbergeben werden, z.B. `/search?q=flask`.
- **Formular-Parameter**: Daten, die im Body einer POST-Anfrage √ºbermittelt werden, z.B. bei einem Login-Formular.
- **AJAX**: Eine Technik, mit der Webanwendungen Daten im Hintergrund laden k√∂nnen, ohne die ganze Seite neu zu laden (Asynchroner Request auf ein Node JS Backend).
- **`fetch()`**: Eine moderne JavaScript-Funktion, mit der Daten asynchron vom Server angefordert werden k√∂nnen.
- **JSON**: Die Javascript Objekt Notation.

# Lernjournal LU05a ‚Äì LU06b: Authentisierung, Autorisierung und Token in Webanwendungen

## Kurzbeschrieb

In diesen Unterrichtsbl√∂cken ging es um die Grundlagen der Authentisierung und Autorisierung in Webanwendungen sowie um moderne Verfahren zur sicheren Identifikation von Benutzern. Dabei wurde insbesondere auf JSON Web Tokens (JWT) eingegangen, die eine zentrale Rolle bei der Realisierung von Sicherheitsmechanismen in verteilten Systemen spielen. Erg√§nzend wurde erkl√§rt, wie man solche Tokens in Clients speichern und bei Requests verwenden kann.

## Lernerfolge

Ich habe ein fundiertes Verst√§ndnis der Unterschiede zwischen **Authentisierung** (Identit√§tsbehauptung) und **Authentifizierung** (Identit√§tspr√ºfung). Besonders spannend war die Unterscheidung der Authentifizierungsarten: z.B. Passwort, SMS-Code und Fingerabdruck.

Die Einf√ºhrung von **Mehr-Faktor-Authentifizierung** sowie Technologien wie **FIDO2** zeigen, wie wichtig es ist, die Benutzeridentit√§t auf mehrere Arten zu √ºberpr√ºfen ‚Äì vor allem im Kontext von Webdiensten mit sensiblen Daten.

---
![Passkey auth](./img/passkey_auth.png)
---

Ein besonderes Aha-Erlebnis hatte ich beim Thema **JWT**: Endlich habe ich wirklich verstanden, wie ein stateless Authentifizierungsmechanismus funktioniert. Dass ein Token nach erfolgreichem Login erstellt, signiert und verschl√ºsselt wird, und dann bei jedem weiteren Request mitgeschickt wird, ist ein simpler aber effizienter Weg die Authentifizierung zu l√∂sen.

## Reflexion

Ich finde es sehr sinnvoll, dass wir in unserer IDPA-Vorabschlussarbeit *Sproutly* genau diese Techniken einsetzen: Wir nutzen JWT und speichern das Token im `sessionStorage`. Das war am Anfang etwas verwirrend, aber durch das Unterrichtsmaterial konnten wir die Konzepte in unsere Applikation erfolgreich einbauen.


## Glossar (in eigenen Worten)

- **Authentisierung**: Ich sage dem System, wer ich bin ‚Äì z.B. durch Eingabe meines Benutzernamens.
- **Authentifizierung**: Das System pr√ºft, ob ich wirklich die Person bin ‚Äì z.B. durch √úberpr√ºfung des Passworts.
- **Autorisierung**: Das System entscheidet, ob ich etwas tun darf ‚Äì z.B. ob ich B√ºcher aus einer Liste abrufen darf.
- **JWT (JSON Web Token)**: Ein kompaktes, verschl√ºsseltes Token, das Informationen √ºber mich enth√§lt, z.B. meine Rolle oder ID.
- **Session Storage**: Ein Zwischenspeicher im Browser, der Daten nur solange aufbewahrt, wie die Seite offen ist.
- **Mehr-Faktor-Authentifizierung (MFA)**: Ich muss mehrere Dinge beweisen, z.B. Passwort + Code auf dem Handy.
- **FIDO2**: Ein Authentifizierungsverfahren ohne Passwort, das z.B. auf Hardware-Token basiert.
- **Single Sign-On (SSO)**: Einmal anmelden, mehrfach nutzen ‚Äì aber nur innerhalb eines bestimmten Kontexts (z.B. derselbe Browser).

# Lernjournal LU07a ‚Äì LU08d: Discovery und Gateway Services

## Kurzbeschrieb

In diesen Lektionen haben wir zwei zentrale Begriffe aus der Welt der verteilten Systeme angeschaut: **Discovery Services** und **Gateway Services**. Beide sind wichtige Bestandteile moderner Architekturen mit Microservices und tragen wesentlich dazu bei, dass solche Systeme **skalierbar**, **zuverl√§ssig** und **flexibel** bleiben.

## Grundlagen Discovery Service

Ein **Discovery Service** sorgt daf√ºr, dass sich verschiedene Services in einem System gegenseitig finden und miteinander kommunizieren k√∂nnen, auch wenn sich ihre IP-Adressen oder Standorte st√§ndig √§ndern. Das ist vor allem in dynamischen Umgebungen wichtig, wie man sie in der Cloud oft hat.

### Aufgaben eines Discovery Services:

- **Registrierung**: Ein Service meldet sich beim Discovery Service an und gibt an, wo er erreichbar ist (IP, Port etc.).
- **Service-Entdeckung**: Andere Services k√∂nnen beim Discovery Service nachfragen, wo sich ein gew√ºnschter Dienst befindet.
- **Dynamische Updates**: Neue Instanzen k√∂nnen automatisch erkannt werden.
- **Fehlerbehandlung**: Wenn ein Service ausf√§llt, wird er aus dem Register entfernt.

Ein bekanntes Beispiel daf√ºr ist **Netflix Eureka** ‚Äì ein Open-Source-Tool zur Verwaltung von Microservices.


## Grundlagen Gateway Service

Ein **Gateway Service** ist der zentrale Einstiegspunkt f√ºr die Kommunikation zwischen einem Client (z.B. ein Browser oder eine Mobile App) und den verschiedenen internen Services eines Systems.

### Funktionen eines Gateway Services:

- **Routing und Weiterleitung**: Weiterleitung von Anfragen an den richtigen Service, je nach URL oder Methode.
- **Transformation**: Konvertierung von Daten in ein einheitliches Format, z.B. JSON.
- **Aggregation**: Zusammenfassen von Antworten mehrerer Services zu einer.
- **Authentifizierung und Autorisierung**: Pr√ºfen von Benutzerrechten mittels z.B. JSON Web Tokens.
- **Lastverteilung**: Gleichm√§ssiges Verteilen der Anfragen auf verschiedene Instanzen.
- **Protokollierung und √úberwachung**: Logging und Sammeln von Metriken zur System√ºberwachung.



Der Gateway √ºbernimmt auch die Aufgabe, **Anfragen zu formatieren** und **Antworten zusammenzustellen**, damit der Client nur mit einer klaren API sprechen muss.

## Unterschiede zwischen Gateway und Discovery

| Merkmal | Gateway Service | Discovery Service |
|--------|------------------|----------------|
| **Zweck** | Schnittstelle zwischen Clients und Services | Verwaltung der Erreichbarkeit von Services |
| **Hauptaufgabe** | Anfragevermittlung, Sicherheit, Logging | Registrierung & Lokalisierung von Services |
| **Wer spricht mit wem?** | Client ‚Üí Gateway ‚Üí Service | Service ‚Üî Discovery ‚Üî Service |
| **Beispiel** | API-Gateway f√ºr Online-Shop | Netflix Eureka |

### Zusammenfassung
Man kann sagen:
- Der **Gateway Service** ist zust√§ndig f√ºr die Kommunikation **von aussen nach innen** (Client ‚Üí System).
- Der **Discovery Service** sorgt daf√ºr, dass die Services **untereinander** wissen, wo sie sich befinden.

## Lernerfolge

Ich habe verstanden, wie Microservices so miteinander verbunden werden k√∂nnen, dass sie auch in komplexen oder verteilten Systemen zuverl√§ssig funktionieren. Besonders wichtig war f√ºr mich das Prinzip der **dynamischen Service-Entdeckung**, bei dem sich neue Dienste automatisch registrieren und auffindbar werden ‚Äì das spart Zeit und reduziert Konfigurationsaufwand.

Beim **Gateway Service** habe ich gelernt, wie man eingehende Anfragen **b√ºndelt**, **weiterleitet** und **pr√ºft**, das alles an einem zentralen Ort. Dadurch kann man die internen Services sauber kapseln und trotzdem von aussen einfach darauf zugreifen.

Ich weiss jetzt, dass diese beiden Dienste oft **Hand in Hand** arbeiten und zusammen die Grundlage f√ºr eine **skalierbare**, **sichere** und **wartbare** Systemarchitektur bilden.

## Lernstrategie

Ich bin so vorgegangen, dass ich zuerst die theoretischen Grundlagen im Unterricht aufgenommen habe. Danach habe ich mir konkrete Beispiele wie **Netflix Eureka** und ein E-Commerce-System angeschaut, um das Ganze besser zu verstehen. Die Visualisierungen und das Aufzeichnen von Abl√§ufen in Skizzen haben mir geholfen, den √úberblick zu behalten.

Zus√§tzlich habe ich weiterf√ºhrende Artikel gelesen, z.B. von Heise und Datacenter Insider, um ein besseres Bild davon zu bekommen, wie diese Konzepte in der Praxis eingesetzt werden. Dabei habe ich mich auf die Funktionsweise konzentriert, statt auf die konkrete Implementierung in einem bestimmten Framework.



## Glossar

- **Discovery Service**: Vermittler zwischen Services, der Adressen & Verf√ºgbarkeiten verwaltet.
- **Gateway Service**: Zentrale Schnittstelle f√ºr Anfragen von Clients.
- **Routing**: Entscheidung, welche Anfrage wohin geht.
- **Netflix Eureka**: Discovery-Service von Netflix, FOSS.

## Bongo Cat Counter
F√ºr dieses Lernjournal wurden 6069 Bongo Cat Taps verwendet, meinem [Bongo K√§tzchen](https://store.steampowered.com/app/3419430/Bongo_Cat/) Bluten die Pf√∂tchen.


# Lernjournal ‚Äì LU09a
## Exploding Kittens: Verteiltes System mit Clowder Service

---

### Kurzbeschrieb
In diesem Unterrichtsblock ging es darum, ein einfaches verteiltes System zu programmieren, das auf dem Spiel *Exploding Kittens* basiert. Dabei kamen sogenannte *Kitten Bots* sowie ein Discovery Service namens **Clowder Service** zum Einsatz.  
Das Hauptthema war die Verbindung und Kommunikation zwischen den Services und dem Clowder Service. Die theoretischen Grundlagen dazu wurden erg√§nzt und im Praxisbeispiel konkret angewendet.

---

### Lernerfolge
- Ich konnte mein bestehendes Wissen aus der letzten Woche direkt anwenden und darauf aufbauen.
- Das Projekt *Exploding Kittens* l√§uft als Standalone und wird noch w√§hrend 5 weiteren Wochen weiterentwickelt.
- Mein gr√∂sster Aha-Moment war, dass ich viele Codeteile aus der Vorwoche wiederverwenden konnte ‚Äì das hat mir viel Zeit gespart.
- Auch wenn es keine grossen neuen Erkenntnisse gab, half mir das schrittweise Rantasten, um Sicherheit im Umgang mit dem Clowder Service zu gewinnen.

---

### Ô∏è Lernstrategie
- Ich habe aktiv auf die **Moodle-Theorien** der letzten Woche zur√ºckgegriffen, was mir beim Verst√§ndnis der Zusammenh√§nge sehr geholfen hat.
- Erg√§nzend habe ich fr√ºhere Artikel und Materialien nochmals konsultiert, um mein Wissen zu festigen.
- Bei einem Problem mit dem Typ `None` bzw. `NoneType` am Anfang habe ich durch Debugging und gezielte Recherchen die L√∂sung gefunden.

---

###  Fazit
Auch wenn keine neuen Inhalte dazukamen, war dieser Block f√ºr mich ein wertvoller Schritt, um Sicherheit mit dem Clowder Service zu gewinnen. Das Wiederverwenden von Code war nicht nur zeitsparend, sondern auch motivierend, da ich gesehen habe, dass mein Vorwissen tr√§gt.  
In den kommenden Wochen werde ich weiterhin auf bew√§hrte Strategien setzen ‚Äì wie etwa das strukturierte Vorgehen mit Moodle-Inhalten ‚Äì und mein Projekt systematisch ausbauen.

## Bongo Cat Counter
F√ºr dieses Lernjournal wurden 2942 Bongo Cat Taps verwendet, meinem [Bongo K√§tzchen](https://store.steampowered.com/app/3419430/Bongo_Cat/) geht langsam die Kraft aus.

![Cute Clowder](./img/clowder.jpg)


# Lernjournal ‚Äì Pub/Sub und MQTT

## Kurzbeschrieb
In diesem Unterrichtsblock haben wir das Kommunikationsmodell **Publish/Subscribe (Pub/Sub)** kennengelernt, das insbesondere im Kontext vom **Internet of Things (IoT)** eine zentrale Rolle spielt. Im Fokus standen die Konzepte hinter Pub/Sub, die beteiligten Komponenten (Publisher, Subscriber, Pub/Sub-System) sowie das leichtgewichtige Protokoll **MQTT**, das dieses Modell in der Praxis umsetzt. Ein besonderes Augenmerk lag auf den Vorteilen der Entkopplung, Skalierbarkeit und Zuverl√§ssigkeit solcher Systeme. Anhand eines Hausautomationsbeispiels wurde aufgezeigt, wie solche Systeme in der Realit√§t funktionieren k√∂nnen.

## Lernerfolge
Ich konnte mir einen klaren √úberblick √ºber die Funktionsweise von Pub/Sub-Systemen verschaffen. Es wurde mir bewusst, wie wichtig die Entkopplung von Publishern und Subscribern ist, um flexible und skalierbare Systeme zu entwickeln. Besonders spannend fand ich das MQTT-Protokoll, das genau f√ºr solche Anforderungen im IoT-Bereich entwickelt wurde. Ich kenne jetzt, was die verschiedenen **QoS-Stufen (Quality of Service)** bedeuten und wie sie sich auf die Nachrichtenzustellung auswirken. Ausserdem wurde mir der Nutzen von Themenstrukturen (z.B. K√ºche/K√ºhlschrank/Temperatur) und retained messages klar.

## Lernstrategie
Meine Strategie war, den empfohlenen Artikel von der Website der Firma EMQX aufmerksam zu lesen. Dabei habe ich mir beim Lesen Notizen gemacht, die wichtigsten Begriffe markiert und das Beispiel mit Publisher und Subscriber in Python nachverfolgt. Um das Ganze besser zu verstehen, habe ich versucht, die Erkl√§rungen in eigenen Worten zusammenzufassen. Dabei habe ich insbesondere darauf geachtet, die Begriffe wie ‚ÄûThema‚Äú, ‚ÄûBroker‚Äú oder ‚ÄûQoS‚Äú richtig einzuordnen. Zudem habe ich auf Moodle nochmal die Theorie aus den vorherigen Wochen zu Pub/Sub durchgelesen ‚Äì das hat mir beim Einordnen des neuen Stoffs sehr geholfen.

## Fazit
Obwohl die Thematik auf den ersten Blick technisch wirkt, ist sie logisch aufgebaut und nachvollziehbar. Die Beispiele und das klare Kommunikationsmodell haben mir geholfen, das Ganze besser zu verstehen. In Zukunft m√∂chte ich MQTT selbst mal ausprobieren und deployen ‚Äì zum Beispiel in einem kleinen Raspberry-Pi oder ESP32 Webserver zu Hause. Durch das strukturierte Lesen und Zusammenfassen kann ich mir neue Inhalte gut erarbeiten ‚Äì diese Strategie m√∂chte ich beibehalten.

## Beispiel
Ein einfaches Beispiel eines solchen Pub/Sub Services ist [NTFY](https://ntfy.sh) welchen ich auch selbst als Docker Container verwende und betreibe.

## Glossar

**Pub/Sub (Publish/Subscribe)**  
Ein Kommunikationsmodell, bei dem Nachrichten von Publishern an ein zentrales System gesendet werden und von dort an alle abonnierten Subscriber verteilt werden. Publisher und Subscriber kennen sich nicht direkt.

**Publisher**  
Ein System oder Ger√§t, das Nachrichten erzeugt und an das Pub/Sub-System sendet.

**Subscriber**  
Ein System oder Ger√§t, das sich f√ºr bestimmte Themen registriert, um passende Nachrichten vom Pub/Sub-System zu empfangen.

**Pub/Sub-System / Broker**  
Die vermittelnde Instanz, die Nachrichten von Publishern entgegennimmt und an alle passenden Subscriber verteilt. In MQTT nennt man diesen Vermittler ‚ÄûBroker‚Äú.

**MQTT (Message Queuing Telemetry Transport)**  
Ein leichtgewichtiges Protokoll, das auf dem Pub/Sub-Modell basiert und speziell f√ºr Ger√§te mit wenig Ressourcen (z.B. im IoT-Bereich) entwickelt wurde.

**Thema (Topic)**  
Ein logischer Kanal, √ºber den Nachrichten organisiert und verteilt werden. Topics k√∂nnen hierarchisch strukturiert sein (z.B. `huus/stube/liecht`).

**Nachricht**  
Die Daten, die ein Publisher sendet und ein Subscriber empf√§ngt. Kann z.B. ein Temperaturwert, ein Ereignis oder ein Text sein.

**QoS (Quality of Service)**  
Die Stufe der Zuverl√§ssigkeit bei der Zustellung einer Nachricht. MQTT kennt drei QoS-Stufen:
- **0**: At most once ‚Äì Nachricht wird einmal gesendet, ohne Best√§tigung.
- **1**: At least once ‚Äì Nachricht wird so lange gesendet, bis sie best√§tigt wurde.
- **2**: Exactly once ‚Äì Nachricht wird genau einmal empfangen, auch bei Verbindungsproblemen.

**Retained Message**  
Eine vom Broker gespeicherte Nachricht, die automatisch an neue Subscriber gesendet wird, sobald sie sich f√ºr ein Thema anmelden.

**Entkopplung**  
Das Prinzip, dass Sender und Empf√§nger von Nachrichten nicht voneinander wissen m√ºssen. Das erh√∂ht die Flexibilit√§t und Wartbarkeit eines Systems.


## Bongo Cat Counter
F√ºr dieses Lernjournal wurden 5485 Bongo Cat Taps verwendet, meine [Bongo K√§tzchen](https://store.steampowered.com/app/3419430/Bongo_Cat/) macht mittlerweile Gebrauch vom Streikrecht.

# Lernjournal: Verteilte Datenhaltung und Apache Cassandra

## Kurzbeschrieb
In diesem Unterrichtsblock ging‚Äôs um die Grundlagen der verteilten Datenhaltung. Ich hab gelernt, wie man Daten √ºber mehrere Rechner verteilt speichert, um die Last besser zu verteilen und wie man so die Skalierbarkeit erh√∂ht. Wir haben auch gelernt, wie Replikation und Partitionierung funktionieren und welche Techniken daf√ºr verwendet werden. Danach haben wir das Ganze mit einer praktischen Analyse von Apache Cassandra vertieft.

## Lernerfolge
- **Verteilte Datenhaltung**: Ich habe verstanden, wie Daten √ºber mehrere Knoten in einem System verteilt werden k√∂nnen und was Replikation und Partitionierung damit zu tun haben.
- **Skalierbarkeit**: Wir haben herausgefunden, wie man die Skalierbarkeit eines Systems verbessert, indem man die Daten auf mehrere Server aufteilt und Anfragen verteilt.
- **Cassandra**: Ich konnte die wichtigsten Features von Cassandra lernen, wie etwa die Replikation und Partitionierung, und wie es mit grossen Datenmengen umgehen kann.

## Lernstrategie
Ich habe den Artikel durchgelesen, die Konzepte und Beispiele analysiert und mir die wichtigsten Punkte notiert. Besonders bei den praktischen Beispielen habe ich viel Wert darauf gelegt, die Replikations- und Partitionierungsstrategien zu verstehen und mir zu merken, welche Optionen Cassandra da bietet. Danach hab ich die Theorie mit der Analyse von Cassandra verkn√ºpft, um zu sehen, wie die Theorie in der Praxis angewendet wird.

## Fazit
Ich habe viel √ºber die Grundlagen der Datenhaltung gelernt und wie das Ganze bei verteilten Systemen wie Cassandra funktioniert. Das Wissen √ºber Replikation, Partitionierung und Konsistenz wird mir sicher in zuk√ºnftigen Projekten helfen, besonders wenn‚Äôs um Systeme mit vielen Daten geht. Die Analyse von Cassandra hat mir auch gezeigt, wie man mit grossen Datenmengen und hohen Zugriffszahlen umgehen kann. Wenn ich in Zukunft ein System aufbaue, das solche Anforderungen hat, k√∂nnte Cassandra echt eine gute Wahl sein.

---

## üìö Glossar

**Verteilte Datenhaltung**: Die Speicherung von Daten auf mehreren Knoten oder Rechnern eines Netzwerks, um Skalierbarkeit, Verf√ºgbarkeit und Ausfallsicherheit zu erh√∂hen.

**Replikation**: Das Anlegen von Kopien derselben Daten auf mehreren Knoten eines Systems, um bei einem Ausfall weiterhin auf die Daten zugreifen zu k√∂nnen.

**Partitionierung**: Die Aufteilung von grossen Datenmengen in kleinere Einheiten, die auf unterschiedlichen Knoten gespeichert werden. Dadurch wird die Last gleichm√§ssiger verteilt.

**ACID**: Ein Konzept aus der klassischen Datenbanktheorie, das f√ºr Transaktionen steht, die atomar, konsistent, isoliert und dauerhaft sein m√ºssen.

**BASE**: Ein alternatives Modell zu ACID, das bei verteilten Systemen h√§ufiger eingesetzt wird. Es steht f√ºr ‚ÄûBasically Available, Soft State, Eventually Consistent‚Äú.

**Eventual Consistency**: Ein Konsistenzmodell, bei dem sichergestellt ist, dass alle Kopien der Daten irgendwann denselben Stand haben ‚Äì aber nicht notwendigerweise sofort.

**Consistent Hashing**: Ein Verfahren zur Partitionierung von Daten, das besonders gut mit dynamisch wechselnden Knotenanzahlen umgehen kann.

**QUORUM**: Ein Konsistenzlevel bei Cassandra, bei dem eine Mehrheit der Knoten antworten muss, um eine Lese- oder Schreiboperation als erfolgreich zu bewerten.

**Cassandra**: Eine verteilte NoSQL-Datenbank, die f√ºr hohe Verf√ºgbarkeit, horizontale Skalierbarkeit und schnelle Verarbeitung grosser Datenmengen entwickelt wurde.

**NoSQL**: Eine Klasse von Datenbanken, die nicht auf relationalen Modellen basiert. Sie sind meist schemalos, horizontal skalierbar und besonders geeignet f√ºr grosse, verteilte Systeme.

## Bongo Cat Counter
F√ºr dieses Lernjournal wurden 4632 Bongo Cat Taps verwendet, mein [Bongo K√§tzchen](https://store.steampowered.com/app/3419430/Bongo_Cat/) ist vom Streik zur√ºckgekehrt und trommelt fleissig weiter. <br>
![Bongo Cat](./img/Bongo_cat.png)

# Lernjournal: √úberwachung und Logging in verteilten Systemen

## Kurzbeschrieb
Verteilte Systeme erfordern effizientes Monitoring und Logging, um ihre Leistung und Zuverl√§ssigkeit sicherzustellen. Monitoring erm√∂glicht das √úberwachen von Systemmetriken wie Latenz und Fehlern, w√§hrend Logging dazu dient, Ereignisse und Fehler detailliert zu dokumentieren. Diese Prozesse sind entscheidend, um Probleme fr√ºhzeitig zu erkennen und schnell zu beheben, was f√ºr den Betrieb gro√üer, verteilter Systeme unverzichtbar ist.

## Lernerfolge
- **Verst√§ndnis der √úberwachungsmetriken:** Ich habe gelernt, welche Metriken wie Latenz, Verkehr und Fehler f√ºr das Monitoring verteilte Systeme relevant sind.
- **Wichtigkeit des Loggings:** Ich habe den Unterschied zwischen zentralisiertem und dezentralisiertem Logging verstanden und wie Logs dabei helfen, Probleme in einem System zu analysieren und zu beheben.
- **Tools kennen gelernt:** Ich bin mit verschiedenen Monitoring- und Logging-Tools vertraut geworden, wie Prometheus, Grafana und dem ELK Stack.

## Lernstrategie
Ich habe dieses Thema durch eine Kombination aus praktischen √úbungen und theoretischen Artikeln erarbeitet. Zun√§chst habe ich mich auf die Grundlagen des Monitorings konzentriert, um die wichtigsten Metriken zu verstehen. Danach habe ich mich mit Logging und dessen Bedeutung f√ºr die Fehlerdiagnose auseinandergesetzt. Parallel dazu habe ich mich mit den Tools besch√§ftigt, indem ich sie in einer lokalen Umgebung eingerichtet habe, um deren Funktionsweise und Anwendung zu verstehen.

## Fazit
Das Monitoring und Logging sind essenziell f√ºr die Fehlerpr√§vention und Performance-Optimierung in verteilten Systemen. Durch dieses Lernen habe ich nicht nur ein tiefes Verst√§ndnis f√ºr die Notwendigkeit dieser Prozesse entwickelt, sondern auch praktische Erfahrungen im Umgang mit g√§ngigen Tools gewonnen. In zuk√ºnftigen Projekten werde ich diese Konzepte und Tools anwenden, um die Qualit√§t und Stabilit√§t der Systeme, an denen ich arbeite, zu gew√§hrleisten.


## Tools f√ºr Monitoring und Logging
F√ºr das Monitoring und Logging in verteilten Systemen gibt es verschiedene Tools, die eine einfache Erfassung und Analyse erm√∂glichen.

### Monitoring-Tools:
- **Prometheus:** Ein Open-Source-Tool, das Zeitserien-Daten erfasst und zur Analyse von Systemmetriken genutzt wird.
- **Grafana:** Ein Dashboard-Tool, das mit Prometheus kombiniert werden kann, um Metriken visuell darzustellen.
- **Zabbix:** Ein weiteres Open-Source-Monitoring-Tool f√ºr Netzwerke und Server, das Alarme und Berichte generiert.

### Logging-Tools:
- **ELK Stack (Elasticsearch, Logstash, Kibana):** Ein weit verbreitetes Logging-Framework, das Logs verarbeitet und analysiert.
- **Fluentd:** Ein weiteres Open-Source-Log-Aggregationstool, das f√ºr die Verarbeitung und Weiterleitung von Logs verwendet wird.

## Zusammenfassung
Das Monitoring und Logging sind fundamentale Bestandteile f√ºr die Verwaltung und Optimierung von verteilten Systemen. Sie erm√∂glichen eine fr√ºhzeitige Erkennung von Problemen und die Durchf√ºhrung gezielter Ma√ünahmen zur Behebung von Fehlern. Tools wie Prometheus, Grafana und der ELK Stack bieten leistungsstarke L√∂sungen, um diese Prozesse zu automatisieren und zu vereinfachen.

## Bongo Cat Counter
F√ºr dieses Lernjournal wurden 4820 Bongo Cat Taps verwendet, mein [Bongo K√§tzchen](https://store.steampowered.com/app/3419430/Bongo_Cat/) wird jetzt ebenfalls als Service mit Prometheus √ºberwacht. <br>